
# ðŸ§  Web Article - Text Mining

## ðŸ“ Objective

This project focuses on **text extraction and natural language processing** to analyze articles from a list of URLs provided in `Input.xlsx`. The goal is to extract the article content and compute a set of textual and linguistic metrics as outlined in the assignment instructions.

---

## ðŸ“‚ Project Structure

```
NLP-Assignment/
â”‚
â”œâ”€â”€ code.py                     # Python script for scraping and text analysis
â”œâ”€â”€ Input.xlsx                  # Contains URLs and URL_IDs
â”œâ”€â”€ Output Data Structure.xlsx # Defines the format and variables for the final output
â”œâ”€â”€ Output.csv                  # Final output file with calculated text features
â”œâ”€â”€ extracted_articles/        # Folder containing .txt files for each extracted article
â”œâ”€â”€ stopwords/                 # Folder containing stopwords files used in analysis
â”‚   â”œâ”€â”€ stopwords-*.txt
â”œâ”€â”€ master_dictionary/         # Folder containing positive and negative word dictionaries
â”‚   â”œâ”€â”€ positive-words.txt
â”‚   â”œâ”€â”€ negative-words.txt
â””â”€â”€ README.md                  # Youâ€™re reading it now!
```

---

## âš™ï¸ Technologies Used

- Python
- `requests`, `BeautifulSoup` â€“ for web scraping
- `nltk`, `re`, `textstat` â€“ for NLP and text feature analysis
- `openpyxl`, `pandas` â€“ for reading and writing Excel files

---

## ðŸ§ª Text Analysis Metrics Computed

Following variables are calculated for each article:

- âœ… POSITIVE SCORE  
- âŒ NEGATIVE SCORE  
- âš–ï¸ POLARITY SCORE  
- ðŸ§  SUBJECTIVITY SCORE  
- ðŸ“ AVG SENTENCE LENGTH  
- ðŸ“Š PERCENTAGE OF COMPLEX WORDS  
- ðŸŒ«ï¸ FOG INDEX  
- ðŸ”¤ AVG NUMBER OF WORDS PER SENTENCE  
- ðŸ§© COMPLEX WORD COUNT  
- ðŸ”¢ WORD COUNT  
- ðŸ”  SYLLABLE PER WORD  
- ðŸ‘¤ PERSONAL PRONOUNS  
- ðŸ“‰ AVG WORD LENGTH  

These metrics help in understanding the sentiment, readability, and linguistic structure of the articles.

---

## ðŸš€ How to Run

### âœ… Prerequisites

Install required dependencies:

```
pip install -r requirements.txt
```

> Example `requirements.txt` content:
```
beautifulsoup4
requests
pandas
openpyxl
nltk
textstat
```

### ðŸ§¾ Steps to Execute

1. **Place the `Input.xlsx`** and **required folders** (`stopwords`, `master_dictionary`) in the same directory as your script.
2. Run the script:

```
python code.py
```

3. The script will:
   - Scrape each article and save it to `extracted_articles/` as a `.txt` file
   - Analyze each text and compute the required metrics
   - Save the results into `Output.csv`
